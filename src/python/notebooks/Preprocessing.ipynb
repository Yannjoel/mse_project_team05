{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run this file one time to preprocess the data.\"\"\"\n",
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from DataHandling.db_reader import Reader\n",
    "from DataHandling.language_processing import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Reading data done\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Reading data...\")\n",
    "reader = Reader()\n",
    "titles = reader.get_titles()\n",
    "bodies = reader.get_bodies()\n",
    "urls = reader.get_urls()\n",
    "reader.close()\n",
    "print(\"Reading data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127642, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"url\": urls, \"body\": bodies, \"title\": titles})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 131\n",
      "Number of duplicates: 59874\n",
      "Number of duplicates: 131\n",
      "Number of duplicates: 89609\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print(\"Number of duplicates:\", df.duplicated().sum())\n",
    "print(\"Number of duplicates:\", df[\"body\"].duplicated().sum())\n",
    "print(\"Number of duplicates:\", df[\"url\"].duplicated().sum())\n",
    "print(\"Number of duplicates:\", df[\"title\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100259\n"
     ]
    }
   ],
   "source": [
    "# drop rows where t端bingen is not contained\n",
    "df = df[\n",
    "    df[\"body\"].str.contains(\"t端bingen\", case=False)\n",
    "    | df[\"title\"].str.contains(\"t端bingen\", case=False)\n",
    "    | df[\"url\"].str.contains(\"t端bingen\", case=False)\n",
    "]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60825\n",
      "55550\n"
     ]
    }
   ],
   "source": [
    "# drop rows with duplicates in column body\n",
    "df.drop_duplicates(subset=[\"body\"], inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "# drop rows with duplicates in column url\n",
    "df.drop_duplicates(subset=[\"url\"], inplace=True)\n",
    "\n",
    "# drop rows where body is empty string\n",
    "df = df[df[\"body\"] != \"\"]\n",
    "\n",
    "# drop rows where title is empty string\n",
    "df = df[df[\"title\"] != \"\"]\n",
    "\n",
    "# drop rows specific to tripadvisor user profiles\n",
    "df = df[~df[\"url\"].str.contains(\"UserReview\")]\n",
    "df = df[~df[\"url\"].str.contains(\"tripadvisor.com/Profile\")]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../../data/bodies.npy\", df[\"body\"].values)\n",
    "np.save(\"../../../data/titles.npy\", df[\"title\"].values)\n",
    "np.save(\"../../../data/urls.npy\", df[\"url\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess data\n",
    "# titles_processed = [preprocess(title) for title in df['title']]\n",
    "# bodies_processed = [preprocess(body) for body in df['body']]\n",
    "\n",
    "# load preprocessed data\n",
    "titles_processed = np.load(\"../../../data/titles_processed.npy\", allow_pickle=True)\n",
    "bodies_processed = np.load(\"../../../data/bodies_processed.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67767,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodies_processed = np.array(bodies_processed, dtype=object)\n",
    "titles_processed = np.array(titles_processed, dtype=object)\n",
    "bodies_processed.shape\n",
    "titles_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as npy-files\n",
    "np.save(\"../../../data/titles_processed.npy\", titles_processed)\n",
    "np.save(\"../../../data/bodies_processed.npy\", bodies_processed)\n",
    "np.save(\"../../../data/urls.npy\", df[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    bodies_processed == np.load(\"../../../data/bodies_processed.npy\", allow_pickle=True)\n",
    ").all()\n",
    "assert (\n",
    "    titles_processed == np.load(\"../../../data/titles_processed.npy\", allow_pickle=True)\n",
    ").all()\n",
    "assert (df[\"url\"] == np.load(\"../../../data/urls.npy\", allow_pickle=True)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
