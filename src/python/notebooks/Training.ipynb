{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from RankingAlgorithms.neuralnetwork import NeuralNetwork\n",
    "from RankingAlgorithms.pwsvm import RankSVM\n",
    "from DataHandling.train_data import load_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'url_bm25': 108, 'url_idf': 18, 'url_vsm': 103,\n",
    "       'url_covered_query_term_number': 3, 'url_query_term_ratio': 8, 'url_stream_length': 13, 'url_n_slash':125, 'url_len_url': 126,\n",
    "       'title_bm25': 107, 'title_idf': 17, 'title_vsm': 102, \n",
    "       'title_covered_query_term_number': 2, 'title_query_term_ratio': 7, 'title_stream_length': 12,\n",
    "       'body_bm25': 105, 'body_idf': 15, 'body_vsm': 100, 'body_covered_query_term_number': 0, 'body_query_term_ratio': 5, 'body_stream_length': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_indices = [108, 18, 103, 3, 8, 13, 125, 126, 107, 17, 102, 2, 7, 12, 105, 15, 100, 0, 5, 10]\n",
    "feature_indices = [108, 18, 103, 3, 8, 126, 107, 17, 102, 2, 7, 12, 105, 15, 100, 0, 5, 10]\n",
    "feature_indices = [108, 103, 3, 8, 107, 102, 2, 7, 105, 100, 0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train, y_train = load_data(path=\"../../../data/MSLR-WEB10K/Fold1/train.txt\", nrows=20000, feature_indices=feature_indices)\n",
    "#X_test, y_test = load_data(path=\"../../../data/MSLR-WEB10K/Fold1/test.txt\", nrows=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts (array([0., 1., 2., 3., 4.]), array([11633,  5644,  2354,   267,   102]))\n"
     ]
    }
   ],
   "source": [
    "print('label counts', np.unique(y_train, return_counts=True))\n",
    "n_samples_per_class = np.unique(y_train, return_counts=True)[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 12) (510,)\n",
      "label counts:  (array([0., 1., 2., 3., 4.]), array([102, 102, 102, 102, 102]))\n"
     ]
    }
   ],
   "source": [
    "# balance dataset\n",
    "indices = []\n",
    "for label in range(5):\n",
    "    indices.append(list(np.random.choice(np.where(y_train == label)[0], n_samples_per_class, replace=False)))\n",
    "    \n",
    "indices = np.array(indices).flatten()\n",
    "\n",
    "X_cut = X_train[indices, :]\n",
    "y_cut = y_train[indices]\n",
    "\n",
    "print(X_cut.shape, y_cut.shape)\n",
    "print('label counts: ', np.unique(y_cut, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = torch.zeros(len(y_cut), 5)\n",
    "for i, label in enumerate(y_cut):\n",
    "    y_trans[i, 0:int(label)+1] = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(n_features=len(feature_indices), n_hidden=10, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define optimizer and loss fct\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.088414  [   32/  510]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5.362634  [   32/  510]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.770411  [   32/  510]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.541931  [   32/  510]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.392932  [   32/  510]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.160458  [   32/  510]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.487248  [   32/  510]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.796001  [   32/  510]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.272980  [   32/  510]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 5.154402  [   32/  510]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.523971  [   32/  510]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4.285190  [   32/  510]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 4.731416  [   32/  510]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 4.317109  [   32/  510]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4.455551  [   32/  510]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 4.710667  [   32/  510]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3.962686  [   32/  510]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 4.434461  [   32/  510]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 5.245046  [   32/  510]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 4.613356  [   32/  510]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 5.010528  [   32/  510]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4.661922  [   32/  510]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4.808910  [   32/  510]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4.597960  [   32/  510]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 5.488620  [   32/  510]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.542638  [   32/  510]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 5.074991  [   32/  510]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.542130  [   32/  510]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4.961580  [   32/  510]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4.763949  [   32/  510]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 4.746340  [   32/  510]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 4.379856  [   32/  510]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 4.713406  [   32/  510]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 4.425908  [   32/  510]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 5.338882  [   32/  510]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 5.596869  [   32/  510]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 5.191594  [   32/  510]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 4.905746  [   32/  510]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 4.655838  [   32/  510]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 4.254379  [   32/  510]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 4.859744  [   32/  510]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 4.324958  [   32/  510]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 4.231124  [   32/  510]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 4.851374  [   32/  510]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 5.246221  [   32/  510]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 4.387429  [   32/  510]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 4.377436  [   32/  510]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 4.281888  [   32/  510]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 4.912903  [   32/  510]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 4.748312  [   32/  510]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 5.344400  [   32/  510]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 4.542629  [   32/  510]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 4.694043  [   32/  510]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 4.169089  [   32/  510]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 3.520743  [   32/  510]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 3.986847  [   32/  510]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 4.549338  [   32/  510]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 5.288510  [   32/  510]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 5.174445  [   32/  510]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 4.487154  [   32/  510]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 4.950327  [   32/  510]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 4.683474  [   32/  510]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 4.858884  [   32/  510]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 5.015338  [   32/  510]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 4.266440  [   32/  510]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 5.237680  [   32/  510]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 4.806818  [   32/  510]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 4.539700  [   32/  510]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 5.077481  [   32/  510]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 4.853275  [   32/  510]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 4.907394  [   32/  510]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 5.066186  [   32/  510]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 4.596993  [   32/  510]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 4.686533  [   32/  510]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 4.051445  [   32/  510]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 5.388186  [   32/  510]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 5.703118  [   32/  510]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 3.986673  [   32/  510]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 4.528176  [   32/  510]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 5.025153  [   32/  510]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 4.411536  [   32/  510]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 5.225845  [   32/  510]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 4.803887  [   32/  510]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 4.375254  [   32/  510]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 5.186509  [   32/  510]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 4.902549  [   32/  510]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 4.172357  [   32/  510]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 4.052589  [   32/  510]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 4.956733  [   32/  510]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 4.365356  [   32/  510]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 4.113780  [   32/  510]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 4.425445  [   32/  510]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 4.432762  [   32/  510]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 5.394834  [   32/  510]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 4.668578  [   32/  510]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 4.371296  [   32/  510]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 5.286722  [   32/  510]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 4.959683  [   32/  510]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 5.604944  [   32/  510]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 5.240565  [   32/  510]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = model.train_loop(torch.Tensor(X_cut), y_trans, loss, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.2\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(torch.Tensor(X_cut))\n",
    "print('accuracy: ', np.sum(np.array(y_pred) == np.array(y_cut)) / len(y_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([408, 102]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(y_pred) == np.array(y_cut), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([510]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999999999994"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg_score(y_cut.reshape(1, -1), y_pred.reshape(1, -1), k=20)\n",
    "ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mdoel\n",
    "model.save(\"../models/nn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brek' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m brek\n",
      "\u001b[0;31mNameError\u001b[0m: name 'brek' is not defined"
     ]
    }
   ],
   "source": [
    "brek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510,)\n",
      "n_samples after pairwise transform  208080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_cut.shape)\n",
    "svm = RankSVM(load=False)\n",
    "svm.fit(X_cut, y_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01502815,  0.32612297, -0.40985204, -0.18505744,  0.02152919,\n",
       "        -0.95838216,  0.24080634,  0.52426169,  0.01029894,  0.07783305,\n",
       "        -0.14635887, -0.21289091]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.67700432e-01, -2.66612348e-01,  9.30984618e-02,  1.38551213e-01,\n",
       "       -8.79487123e-02, -4.12904771e-01, -1.41773453e-01,  4.44130485e-01,\n",
       "       -2.66880706e-03, -3.58039834e-01, -8.44252895e-01, -1.75034810e-01,\n",
       "       -3.05181127e-01, -4.99293373e-02, -7.23188334e-01, -2.58073899e-02,\n",
       "       -3.65801300e-01, -4.77305980e-01, -1.44553992e-02, -9.44672396e-02,\n",
       "        2.73010049e-01, -3.21902281e-01,  5.20510365e-01,  6.79101748e-02,\n",
       "       -2.29674146e-01, -7.11919955e-01,  0.00000000e+00,  1.16986746e-02,\n",
       "       -3.03102930e-01,  0.00000000e+00, -4.82464392e-01, -1.15212065e-01,\n",
       "        1.94942871e-02,  2.40949424e-02,  1.86273482e-01,  1.17665668e-01,\n",
       "       -1.13881659e+00, -4.86174689e-02,  1.90833539e-02, -5.10502131e-02,\n",
       "        4.64561930e-01, -8.01217767e-01, -2.75778584e-01, -9.56512820e-02,\n",
       "       -2.98521939e-01, -2.22161531e-01, -2.76150975e-01, -1.91943354e-01,\n",
       "       -4.29995385e-01, -4.55238784e-01,  8.28749414e-03,  4.42029925e-01,\n",
       "        7.89158571e-02, -1.10104706e-01,  2.85399053e-01,  9.70631820e-02,\n",
       "       -3.22451908e-01,  1.71723430e-01, -2.53405428e-01, -2.35541454e-01,\n",
       "       -6.83513900e-01, -1.75336871e-01, -3.83449370e-01, -3.69194421e-01,\n",
       "       -1.35242953e-01, -3.52273710e-01, -7.28467317e-01,  2.86720114e-01,\n",
       "        0.00000000e+00, -2.30054759e-01, -3.65905485e-01, -1.58211637e-01,\n",
       "       -8.23871367e-02, -1.01708783e-01, -1.03078936e-01, -7.48088836e-02,\n",
       "       -3.14498664e-01,  0.00000000e+00, -1.85099469e-01, -2.55293041e-01,\n",
       "        6.57637565e-02, -2.99629406e-01,  0.00000000e+00, -1.51811736e-01,\n",
       "        2.52877257e-01, -8.41750998e-01,  0.00000000e+00, -3.29191419e-01,\n",
       "        2.94154519e-01, -9.25545437e-01, -9.70395880e-01, -8.19064100e-02,\n",
       "       -4.54513395e-02, -2.59637355e-01,  0.00000000e+00, -5.02607192e-01,\n",
       "       -4.39112278e-01, -6.68548146e-01, -3.76310754e-01, -3.43589229e-02,\n",
       "        1.28409416e-01, -2.27869802e-01, -6.14960382e-01,  2.23962354e-01,\n",
       "       -1.00113634e-01,  4.68500084e-01, -1.62147025e-01,  4.04043245e-01,\n",
       "        1.47313536e-01,  8.06111822e-02, -3.04044139e-01,  0.00000000e+00,\n",
       "       -1.72184514e-01, -7.99517487e-01,  1.51686494e-01, -6.82728874e-02,\n",
       "        3.34073025e-02,  0.00000000e+00, -1.67760766e-01,  4.84062541e-02,\n",
       "       -4.14716412e-01,  8.10486567e-01, -8.92996614e-01, -9.50822748e-01,\n",
       "        0.00000000e+00,  6.97581042e-01,  5.92755407e-02, -1.38341357e-01,\n",
       "        6.95487388e-02,  4.99074037e-01, -1.37135810e-03,  4.13470477e-01,\n",
       "       -1.89396259e-01,  1.04642521e+00, -3.36474959e-01,  8.53174537e-01,\n",
       "       -2.14372011e-01, -3.30330912e-01,  2.18076814e-01, -3.79631491e-01,\n",
       "       -7.91923471e-02, -2.98918128e-02,  1.13183431e-01, -3.38329592e-01,\n",
       "       -9.18513229e-02,  5.84142410e-01, -1.18355391e-01, -1.90766522e-01,\n",
       "       -1.37285652e-01, -3.15337997e-01, -1.36326636e-01, -1.83815888e-01,\n",
       "       -3.00833092e-01,  3.43623790e-01, -3.55800367e-02,  2.33289495e-01,\n",
       "        3.77070658e-01, -3.40837071e-01,  1.14174701e-01,  1.17797320e-01,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.36707658e-01, -2.61705421e-01,\n",
       "       -2.28822222e-02,  8.83146240e-02, -3.73567776e-02, -1.34032426e-01,\n",
       "       -4.73330283e-01, -2.07264142e-01,  2.22535553e-01,  4.14239976e-02,\n",
       "       -1.02063572e+00, -2.71262692e-01,  1.27708504e-01, -1.20091139e-01,\n",
       "       -1.54766987e-01,  1.84076473e-01, -8.28304733e-02,  2.84471796e-01,\n",
       "       -8.91346452e-02,  1.05201751e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -6.40082918e-01, -4.84610294e-01, -5.01592374e-01, -8.30548232e-02,\n",
       "        2.47258837e-01, -9.78890070e-02, -1.34818509e-01, -3.79371654e-01,\n",
       "       -1.72699729e-01, -4.45051132e-02,  1.97848419e-01, -1.95579012e-02,\n",
       "       -1.84859609e-01, -4.17528554e-01,  2.46466269e-03, -1.25480435e-02,\n",
       "        1.12001801e-01, -1.89627152e-01,  3.62575338e-01, -4.17489925e-01,\n",
       "       -1.97004964e-01,  3.77688384e-01, -4.17943905e-01, -4.18504947e-01,\n",
       "        6.37309672e-01,  4.65111164e-01,  3.98388769e-01, -1.48206822e-01,\n",
       "        2.57643047e-01, -2.99876219e-03, -2.92053309e-01, -6.79593700e-01,\n",
       "       -1.40987875e-01, -1.78964051e-01, -6.41029667e-02, -8.60838690e-02,\n",
       "        1.95921862e-01, -4.40294533e-01, -9.28928903e-02, -3.56373647e-01,\n",
       "       -1.02488360e-01, -4.65160870e-02,  1.90201529e-02,  1.78319221e-01,\n",
       "        0.00000000e+00,  2.14512159e-01, -2.85864741e-01,  1.65609892e-01,\n",
       "       -2.04388017e-01,  1.67021918e-01, -1.14195537e-01,  6.77570332e-02,\n",
       "        2.65375313e-01, -3.18649639e-02, -1.31094450e-01,  4.15809161e-01,\n",
       "       -2.82279973e-01,  2.96856664e-02, -1.27641992e-01,  5.18085683e-01,\n",
       "       -2.02702428e-01, -9.73922574e-02, -1.71054307e-01, -5.99901781e-01,\n",
       "        1.17313832e+00,  5.06633955e-01,  5.42700849e-01, -4.70482643e-02,\n",
       "        8.38981774e-02,  2.23859750e-01,  5.55388841e-01,  0.00000000e+00,\n",
       "        6.48095844e-01, -2.11305173e-02, -4.48365964e-01, -6.80628251e-02,\n",
       "        1.92479027e-01, -1.72613126e-01,  0.00000000e+00,  7.65366549e-01,\n",
       "        0.00000000e+00, -3.36865342e-01,  6.09595731e-01, -4.23629494e-01,\n",
       "       -3.61239383e-01, -3.84724512e-01,  5.98673613e-01,  1.35530401e-01,\n",
       "        2.22751511e-01,  8.46722371e-02, -9.60068509e-01,  1.44109360e-01,\n",
       "       -1.57599592e-01,  1.87972716e-01,  0.00000000e+00, -4.44043748e-02,\n",
       "       -2.40520524e-01,  3.55266555e-02,  3.13507460e-02,  5.31320068e-01,\n",
       "        0.00000000e+00,  7.72577734e-02, -8.25754296e-01,  2.33737634e-01,\n",
       "       -7.20264245e-02,  1.86736705e-01, -9.01480611e-02,  3.28665654e-01,\n",
       "        2.64115654e-01, -3.00939547e-01, -8.93603896e-02,  5.81444791e-02,\n",
       "        4.38736426e-01, -1.68565812e-01, -5.28953045e-01,  5.45579528e-01,\n",
       "       -2.59991606e-01,  1.74146976e-02,  1.09834489e-01,  3.48364166e-01,\n",
       "        3.66540619e-02, -1.93216804e-01,  1.37084749e-01, -4.84051278e-01,\n",
       "       -2.40293451e-01, -7.69790038e-04, -8.95901597e-02,  6.89108034e-02,\n",
       "        0.00000000e+00, -3.44587527e-01,  1.79753847e-01,  2.99751577e-01,\n",
       "       -1.43582188e-01,  1.17700486e-01, -7.28040387e-01,  2.58832825e-01,\n",
       "        4.09219829e-01,  9.20063105e-02,  3.58519529e-01, -2.33561606e-01,\n",
       "       -2.65971335e-01, -2.40293451e-01, -4.96365043e-02,  2.87588447e-02,\n",
       "        1.67130479e-01,  1.98400286e-01, -5.71043435e-02, -3.38507906e-02,\n",
       "       -2.76591433e-01, -6.19788063e-01,  2.34060518e-01,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.83452084e-01, -1.24050124e-01,  1.65401823e-01,\n",
       "        1.92742853e-01,  2.66009144e-01, -3.12830750e-01,  6.86588193e-02,\n",
       "        2.00739604e-01,  4.39716393e-01, -2.46009260e-01, -1.09210378e-02,\n",
       "        4.70245863e-01,  1.28536326e-01,  4.31890190e-01, -1.18618978e-01,\n",
       "        4.03252996e-01,  2.52811061e-01, -6.80297124e-02,  4.23883324e-01,\n",
       "        4.15206802e-01,  1.12828574e-01, -2.20873097e-01, -2.96405377e-01,\n",
       "        2.22492771e-01,  1.97805961e-01, -1.91635898e-01, -4.39216275e-01,\n",
       "        3.02980760e-01, -4.50686435e-01, -7.65022023e-02,  0.00000000e+00,\n",
       "       -4.96443624e-02, -7.46244703e-01,  3.43047984e-01,  4.07858783e-01,\n",
       "        2.36858421e-01,  1.89921490e-01, -6.05716393e-02,  1.67728248e-01,\n",
       "        2.40448876e-01,  9.83571291e-02,  6.46772076e-02, -4.52044120e-01,\n",
       "        0.00000000e+00, -1.70835206e-01,  3.69128949e-02,  1.28865140e-01,\n",
       "        4.19548189e-01, -2.56346701e-01, -1.19508232e-01, -4.05783100e-01,\n",
       "       -1.80898385e-01, -3.23335080e-01,  2.22751511e-01,  4.54947597e-01,\n",
       "       -2.66563141e-02, -1.28436532e-01,  1.18745995e-01,  4.93926695e-01,\n",
       "        5.50171561e-02, -2.48372599e-01, -3.27685928e-01, -2.25205545e-01,\n",
       "       -1.20465810e-02, -1.91635898e-01,  1.31427567e-01,  1.00588824e-01,\n",
       "        6.03167175e-01,  4.03252996e-01, -9.17840785e-02, -2.22256821e-01,\n",
       "       -1.01133527e-01, -2.69379783e-01, -3.06498096e-02,  6.37484766e-01,\n",
       "        6.36494207e-02,  1.95625995e-01,  1.40727222e-01,  0.00000000e+00,\n",
       "        4.37748808e-01,  6.00033309e-02, -1.73237963e-01,  6.29657539e-01,\n",
       "        4.53223821e-01, -1.18228715e-01, -5.52047479e-01,  5.48285523e-01,\n",
       "        1.35530401e-01,  2.81751677e-01,  2.85950374e-01, -1.66504484e-01,\n",
       "        2.18875614e-02,  0.00000000e+00,  5.75776519e-01,  1.96511113e-01,\n",
       "       -1.11771591e-01, -7.31079788e-02, -2.48371574e-01,  8.75888948e-01,\n",
       "        6.10772490e-01, -1.36646082e-01,  6.55278742e-01,  4.59024029e-01,\n",
       "       -3.62342266e-01,  1.01212309e+00,  1.86897921e-01,  6.36494207e-02,\n",
       "        2.55293633e-01,  1.34370925e-01,  3.40517154e-01,  6.36494207e-02,\n",
       "       -3.45119291e-01,  1.50812953e-01,  1.97805961e-01,  3.72457304e-01,\n",
       "       -6.63222586e-02,  5.50866436e-01,  2.37159232e-01,  3.47599166e-01,\n",
       "       -2.84852503e-01,  2.69712793e-01,  1.65547959e-01, -1.54731037e-02,\n",
       "        3.76240149e-02,  6.37513938e-01,  2.85950374e-01,  0.00000000e+00,\n",
       "        1.80699875e-01,  6.37298098e-01, -2.45995057e-01,  6.10772490e-01,\n",
       "        3.15745505e-02,  5.12588429e-01,  4.02569818e-01,  1.01212309e+00,\n",
       "        0.00000000e+00,  6.71081458e-01,  6.10772490e-01,  6.37164286e-01,\n",
       "       -4.32860826e-03,  1.03533708e-01,  5.50171561e-02,  9.07867088e-02,\n",
       "       -7.18868746e-03,  1.78768649e-01,  7.39925992e-01,  4.02569818e-01,\n",
       "        5.09625276e-01,  5.50866436e-01,  1.40727222e-01,  4.02569818e-01,\n",
       "       -3.62342266e-01,  8.53702579e-02,  5.12588429e-01,  6.10772490e-01,\n",
       "        1.53901080e-01,  0.00000000e+00,  6.37651800e-01,  6.37596318e-01,\n",
       "        4.29374106e-02, -1.94382121e-01,  1.50812953e-01,  3.72243601e-01,\n",
       "        4.60412057e-01,  3.29609118e-01,  3.38619492e-01,  9.07867088e-02,\n",
       "        0.00000000e+00,  1.99879083e-01,  1.67524189e-01, -1.54731037e-02,\n",
       "       -1.54731037e-02,  5.67346930e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svm.predict(X_cut)\n",
    "svm.save(\"../models/ranksvm.pkl\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589554438519665"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg_score(y_cut.reshape(1, -1), preds.reshape(1, -1), k=10)\n",
    "ndcg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
