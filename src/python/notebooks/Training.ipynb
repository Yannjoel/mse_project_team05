{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from RankingAlgorithms.neuralnetwork import NeuralNetwork\n",
    "from RankingAlgorithms.pwsvm import RankSVM\n",
    "from DataHandling.train_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    \"url_bm25\": 108,\n",
    "    \"url_idf\": 18,\n",
    "    \"url_vsm\": 103,\n",
    "    \"url_covered_query_term_number\": 3,\n",
    "    \"url_query_term_ratio\": 8,\n",
    "    \"url_stream_length\": 13,\n",
    "    \"url_n_slash\": 125,\n",
    "    \"url_len_url\": 126,\n",
    "    \"title_bm25\": 107,\n",
    "    \"title_idf\": 17,\n",
    "    \"title_vsm\": 102,\n",
    "    \"title_covered_query_term_number\": 2,\n",
    "    \"title_query_term_ratio\": 7,\n",
    "    \"title_stream_length\": 12,\n",
    "    \"body_bm25\": 105,\n",
    "    \"body_idf\": 15,\n",
    "    \"body_vsm\": 100,\n",
    "    \"body_covered_query_term_number\": 0,\n",
    "    \"body_query_term_ratio\": 5,\n",
    "    \"body_stream_length\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_indices = [108, 103, 3, 8, 107, 102, 2, 7, 105, 100, 0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train, y_train = load_data(\n",
    "    path=\"../../../data/MSLR-WEB10K/Fold1/train.txt\",\n",
    "    nrows=20000,\n",
    "    feature_indices=feature_indices,\n",
    ")\n",
    "# X_test, y_test = load_data(path=\"../../../data/MSLR-WEB10K/Fold1/test.txt\", nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts (array([0., 1., 2., 3., 4.]), array([11633,  5644,  2354,   267,   102]))\n"
     ]
    }
   ],
   "source": [
    "print(\"label counts\", np.unique(y_train, return_counts=True))\n",
    "n_samples_per_class = np.unique(y_train, return_counts=True)[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 12) (510,)\n",
      "label counts:  (array([0., 1., 2., 3., 4.]), array([102, 102, 102, 102, 102]))\n"
     ]
    }
   ],
   "source": [
    "# balance dataset\n",
    "indices = []\n",
    "for label in range(5):\n",
    "    indices.append(\n",
    "        list(\n",
    "            np.random.choice(\n",
    "                np.where(y_train == label)[0], n_samples_per_class, replace=False\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "indices = np.array(indices).flatten()\n",
    "\n",
    "X_cut = X_train[indices, :]\n",
    "y_cut = y_train[indices]\n",
    "\n",
    "print(X_cut.shape, y_cut.shape)\n",
    "print(\"label counts: \", np.unique(y_cut, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = torch.zeros(len(y_cut), 5)\n",
    "for i, label in enumerate(y_cut):\n",
    "    y_trans[i, 0 : int(label) + 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(n_features=len(feature_indices), n_hidden=10, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define optimizer and loss fct\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.053125  [   32/  510]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.493237  [   32/  510]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5.383163  [   32/  510]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.882262  [   32/  510]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.678925  [   32/  510]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 5.126726  [   32/  510]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.173510  [   32/  510]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.921635  [   32/  510]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 5.885022  [   32/  510]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.118716  [   32/  510]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 5.073897  [   32/  510]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 5.326819  [   32/  510]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 5.017152  [   32/  510]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 4.954721  [   32/  510]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4.169617  [   32/  510]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 5.021899  [   32/  510]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 5.229969  [   32/  510]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 5.113085  [   32/  510]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 4.684711  [   32/  510]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 4.744322  [   32/  510]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 4.618107  [   32/  510]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4.799516  [   32/  510]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4.513844  [   32/  510]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4.829933  [   32/  510]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.736619  [   32/  510]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.236946  [   32/  510]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.443558  [   32/  510]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.671599  [   32/  510]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4.191834  [   32/  510]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4.289855  [   32/  510]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 4.824724  [   32/  510]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 4.765244  [   32/  510]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 4.495273  [   32/  510]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 4.996466  [   32/  510]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 4.879169  [   32/  510]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 4.396333  [   32/  510]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 5.088271  [   32/  510]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 4.718356  [   32/  510]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 5.020815  [   32/  510]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 4.431241  [   32/  510]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 4.650267  [   32/  510]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 4.873203  [   32/  510]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 5.298249  [   32/  510]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 4.590571  [   32/  510]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 5.396572  [   32/  510]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 5.617298  [   32/  510]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 4.544673  [   32/  510]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 4.719533  [   32/  510]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 3.898349  [   32/  510]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 4.288445  [   32/  510]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 4.983229  [   32/  510]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 4.005545  [   32/  510]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 4.819274  [   32/  510]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 4.806581  [   32/  510]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 4.398417  [   32/  510]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 5.025820  [   32/  510]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 4.855264  [   32/  510]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 4.432294  [   32/  510]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 4.119656  [   32/  510]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 4.640444  [   32/  510]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 4.175097  [   32/  510]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 4.646249  [   32/  510]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 4.599226  [   32/  510]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 4.973093  [   32/  510]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 5.030341  [   32/  510]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 4.275862  [   32/  510]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 4.802618  [   32/  510]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 5.098632  [   32/  510]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 5.183434  [   32/  510]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 4.658292  [   32/  510]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 5.085909  [   32/  510]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 4.602123  [   32/  510]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 4.584734  [   32/  510]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 5.666316  [   32/  510]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 4.756114  [   32/  510]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 4.969773  [   32/  510]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 5.460009  [   32/  510]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 4.161040  [   32/  510]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 4.225266  [   32/  510]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 5.283969  [   32/  510]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 4.550979  [   32/  510]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 5.194089  [   32/  510]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 4.377820  [   32/  510]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 4.540831  [   32/  510]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 3.520957  [   32/  510]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 4.698460  [   32/  510]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 5.239531  [   32/  510]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 4.270525  [   32/  510]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 4.217117  [   32/  510]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 4.767442  [   32/  510]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 4.433809  [   32/  510]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 4.921123  [   32/  510]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 5.133334  [   32/  510]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 5.009384  [   32/  510]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 5.232678  [   32/  510]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 4.881793  [   32/  510]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 4.592700  [   32/  510]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 4.590846  [   32/  510]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 4.692935  [   32/  510]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 4.982786  [   32/  510]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = model.train_loop(torch.Tensor(X_cut), y_trans, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.2\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(torch.Tensor(X_cut))\n",
    "print(\"accuracy: \", np.sum(np.array(y_pred) == np.array(y_cut)) / len(y_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([408, 102]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(y_pred) == np.array(y_cut), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([510]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mdoel\n",
    "model.save(\"../models/nn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pairwise SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510,)\n",
      "n_samples after pairwise transform  208080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_cut.shape)\n",
    "svm = RankSVM(load=False)\n",
    "svm.fit(X_cut, y_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95995110e-02,  5.48621345e-01, -2.76093827e-01,\n",
       "        -5.36713077e-02,  3.12683148e-02, -9.44029517e-01,\n",
       "         3.53660647e-01,  2.08883665e-01, -9.03992095e-04,\n",
       "         3.09513406e-01, -1.84403838e-01, -4.18891355e-01]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38803354e-01, -4.14875045e-01, -1.43879255e-01,  5.41011609e-01,\n",
       "       -2.38905598e-01,  4.96032265e-01, -9.49175300e-02, -5.16240497e-01,\n",
       "       -3.94080586e-01,  3.55587383e-01, -6.74226052e-01, -3.20007929e-01,\n",
       "       -2.68118622e-01, -7.30816202e-01, -4.35178722e-01, -5.93375223e-01,\n",
       "       -5.07496430e-01, -3.40385826e-01, -1.04951655e-02, -3.74342423e-01,\n",
       "       -7.20876588e-02, -5.53036042e-01,  0.00000000e+00, -1.32677315e+00,\n",
       "       -1.65350843e-01, -3.37485859e-01, -6.44301903e-01, -2.52630959e-01,\n",
       "       -1.06600078e-01, -3.76867047e-01,  1.76459791e-01, -4.46861618e-01,\n",
       "        2.17634220e-01,  0.00000000e+00, -6.68662784e-01, -3.71070175e-01,\n",
       "        3.97204229e-01,  2.13293289e-01,  4.23715351e-01,  6.46698084e-01,\n",
       "       -7.29333630e-02,  0.00000000e+00,  9.05004644e-02, -6.95308835e-01,\n",
       "       -4.00534267e-01, -6.31000720e-01,  1.67356641e-01, -6.86820252e-01,\n",
       "        3.55058593e-02, -4.91707362e-01,  6.36003950e-01, -4.93488122e-01,\n",
       "       -1.20811576e-01, -6.87518601e-01, -8.66127494e-01, -3.44997744e-01,\n",
       "       -1.99531016e-01, -2.60970393e-01, -2.21402061e-01,  0.00000000e+00,\n",
       "       -5.65340714e-01, -6.28218362e-01, -3.73961470e-01, -9.18012678e-01,\n",
       "        9.99201891e-02,  3.20441579e-01,  0.00000000e+00, -5.04677743e-01,\n",
       "       -3.01964855e-01, -5.02058908e-01, -6.54511765e-01,  0.00000000e+00,\n",
       "       -3.22661296e-01, -1.35381672e-02, -9.37337392e-01,  0.00000000e+00,\n",
       "       -9.33804161e-01, -3.36272409e-01,  1.06048404e-01, -7.98496657e-01,\n",
       "        1.40341479e-02, -6.38169056e-02, -1.71541844e-01,  1.54950597e-01,\n",
       "        6.78492557e-01,  3.16317411e-01, -4.07555425e-01,  0.00000000e+00,\n",
       "        5.76272218e-01, -2.12103839e-01,  6.26105375e-02, -2.95598791e-02,\n",
       "        5.78827521e-01,  4.86674876e-01, -5.96175294e-01, -4.15030475e-01,\n",
       "       -5.17533671e-01, -5.45695780e-01,  3.63460980e-01, -2.99859213e-01,\n",
       "       -3.02445022e-01, -3.30554094e-01, -2.00550252e-01,  3.45591957e-01,\n",
       "       -4.05817559e-01, -1.72321112e-01, -4.18144684e-01,  2.80959672e-02,\n",
       "       -1.91605102e-01,  5.92749276e-01, -2.55654129e-01, -5.91891871e-01,\n",
       "       -1.51631512e-01, -3.07186347e-01, -3.35771044e-01,  1.29043590e-01,\n",
       "       -5.21430403e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.26114764e-02, -1.69988709e-01, -1.91062779e-01,  0.00000000e+00,\n",
       "       -1.90837984e-02,  1.69153280e-02,  1.96455722e-01, -4.05226146e-01,\n",
       "       -2.14489996e-01,  2.26120769e-01, -4.23369948e-01,  2.45135452e-01,\n",
       "       -1.10495397e-01, -1.50160693e-01,  1.47211551e-01, -3.05151290e-01,\n",
       "       -3.77240609e-02, -1.03308679e-01,  4.77910766e-01,  2.17939610e-01,\n",
       "        1.87711859e-01,  0.00000000e+00,  7.15317713e-02,  3.71492586e-01,\n",
       "        4.08236039e-01, -3.04044654e-01,  3.03868275e-01,  3.26655226e-01,\n",
       "       -4.20660097e-02,  0.00000000e+00, -6.58956688e-02,  3.57795827e-03,\n",
       "        6.50623899e-01,  1.46990973e-01,  4.28164064e-01,  0.00000000e+00,\n",
       "       -9.54397287e-02,  7.83020817e-02, -2.24672362e-01, -2.97852290e-01,\n",
       "       -5.32967122e-01,  1.53788938e-01,  2.19153131e-01,  4.10983160e-01,\n",
       "       -3.13018020e-01, -1.25122738e-01,  5.43414853e-04, -3.03159968e-01,\n",
       "       -1.36094523e-04,  0.00000000e+00, -5.41419269e-01, -5.05311742e-01,\n",
       "       -1.00976477e+00, -1.03122380e-01, -1.26380575e-01, -3.75218413e-01,\n",
       "       -8.08687759e-01, -3.15418684e-01,  1.44134225e-01, -5.30430370e-01,\n",
       "       -1.51651793e-01,  0.00000000e+00,  3.09439984e-02, -5.11173173e-01,\n",
       "       -2.66092654e-01,  1.23760042e-02,  0.00000000e+00,  1.11012621e-02,\n",
       "       -2.21840758e-01,  4.43585078e-01,  1.71342975e-01, -3.81946021e-01,\n",
       "        2.08422919e-01, -6.07927338e-01, -5.13659584e-01, -5.89779194e-02,\n",
       "       -1.01680940e-01, -1.15082659e+00, -1.31731184e-01, -5.85083315e-01,\n",
       "        8.87222393e-01,  0.00000000e+00, -2.01151074e-01, -3.26133889e-01,\n",
       "       -4.20785408e-01,  2.75226156e-03,  1.38877608e-01,  2.12745276e-01,\n",
       "       -4.26414756e-01, -7.07250495e-03,  1.10921016e-01, -4.67657224e-01,\n",
       "        3.23206154e-01, -1.79318243e-01,  7.41631739e-02, -1.69242924e-03,\n",
       "        4.82631168e-01,  5.49255773e-01,  2.74120901e-01,  1.80579258e-01,\n",
       "        5.14262623e-01, -7.10264230e-01,  3.53729770e-01,  6.57503172e-01,\n",
       "        1.02559642e-01, -1.59944182e-01, -2.56717742e-01, -5.11260940e-01,\n",
       "        5.20728747e-01, -1.25287689e-02,  5.70099646e-01,  9.72070815e-02,\n",
       "        3.56211784e-01, -4.66585750e-02, -1.21399386e-01, -1.55884856e-01,\n",
       "        5.73335779e-01, -2.12858669e-02,  0.00000000e+00, -5.66120954e-02,\n",
       "        3.58228698e-01,  4.54183802e-01,  3.83175002e-01, -5.18066994e-01,\n",
       "       -4.27032196e-01, -4.29160731e-01,  2.16105282e-01, -2.00281531e-01,\n",
       "       -6.20357370e-01,  1.85679804e-01, -3.26273226e-01, -8.87763335e-02,\n",
       "        4.29134765e-01, -1.33276737e-01,  3.13483362e-01,  7.03683718e-03,\n",
       "        3.53966734e-01, -1.03395257e-01,  6.64074530e-01, -2.32504447e-01,\n",
       "       -1.27483083e-01,  4.01658226e-01,  2.45289765e-01,  3.94345438e-01,\n",
       "       -3.07090540e-01,  2.66890120e-01, -5.10487028e-01,  2.33231834e-01,\n",
       "        9.44971731e-02,  4.10990243e-01, -4.50571439e-01,  6.58202305e-01,\n",
       "        3.84792170e-01,  6.87463535e-03,  6.01939318e-01, -2.14917541e-01,\n",
       "        0.00000000e+00,  8.06549697e-02,  0.00000000e+00, -6.96159592e-02,\n",
       "        1.64637684e-01,  6.92081731e-02,  1.35092307e-01,  5.00341352e-01,\n",
       "        1.12722548e-02,  1.36650569e-01, -6.74288450e-01,  2.39491041e-01,\n",
       "        5.36682865e-01,  7.85127019e-01,  4.30468812e-01, -2.38624047e-01,\n",
       "        7.03910871e-01,  5.68434110e-01,  4.38518654e-01,  1.80327128e-01,\n",
       "        0.00000000e+00,  7.76519332e-01,  4.15288238e-01, -2.31432283e-01,\n",
       "        3.12289275e-01, -1.26276932e-01,  3.18226320e-01, -1.55600673e-01,\n",
       "       -5.68999974e-01, -2.23856378e-01, -3.33090572e-01, -3.69797120e-01,\n",
       "        3.35523900e-01,  4.54519938e-01,  0.00000000e+00,  3.46970962e-01,\n",
       "        3.26615814e-01,  0.00000000e+00,  4.61528379e-02,  3.85033135e-01,\n",
       "        3.35398833e-01,  1.50931352e-01, -2.24444020e-01, -5.64611903e-01,\n",
       "        2.90543725e-01, -8.53226053e-02,  2.67896574e-01, -1.87365931e-01,\n",
       "       -4.46353006e-01, -3.71845833e-02,  2.47384981e-01, -9.21539878e-02,\n",
       "       -6.64381066e-01,  1.03838721e-01, -1.87365931e-01,  6.12862697e-01,\n",
       "        1.51646988e-01,  2.54595637e-01,  4.28530282e-01,  2.14731166e-01,\n",
       "       -2.78340645e-01, -1.15291102e-02, -1.18209106e-01,  3.26794892e-01,\n",
       "        4.83397830e-01,  1.84820150e-01,  2.28809016e-01, -2.98803438e-01,\n",
       "        4.71958313e-01,  0.00000000e+00, -5.00937848e-01,  6.51590529e-01,\n",
       "       -4.21322773e-01, -2.90258683e-01, -4.76338452e-01,  0.00000000e+00,\n",
       "        5.98715017e-02,  9.85747013e-02, -3.15561419e-01, -5.10913414e-01,\n",
       "        3.51021427e-01,  8.60430821e-01,  0.00000000e+00, -3.03205762e-01,\n",
       "        2.61156570e-01,  3.16155392e-03,  1.96936060e-01,  7.17861120e-01,\n",
       "       -5.61666964e-02,  4.74881521e-01,  7.58132791e-02,  5.53693040e-01,\n",
       "       -4.81508096e-01,  1.79877430e-01,  2.57003174e-01,  0.00000000e+00,\n",
       "       -1.34553010e-01,  3.65037248e-02, -1.12031965e-01, -4.72466924e-01,\n",
       "        1.23776320e-01,  0.00000000e+00,  3.54057190e-01,  3.70770826e-01,\n",
       "       -1.24716012e-01,  7.05544840e-02,  2.44850598e-01, -9.93305143e-02,\n",
       "       -3.14125676e-01,  1.47314625e-01,  5.70230985e-01,  1.36762963e-01,\n",
       "       -3.02051831e-01, -5.79244812e-02, -2.87871469e-01,  1.83477891e-01,\n",
       "        2.84313267e-01,  4.28164064e-01,  6.07267323e-01,  2.38037288e-01,\n",
       "        5.52956314e-01,  2.21971426e-02,  7.17884582e-01,  2.80256853e-01,\n",
       "       -1.25610044e-01, -3.14126365e-01,  3.71399982e-01,  4.88957173e-01,\n",
       "       -6.80155414e-02,  4.46655172e-01,  3.76426723e-02, -5.00937848e-01,\n",
       "        2.01747386e-01, -6.93858704e-01,  9.90869984e-02,  2.14731166e-01,\n",
       "        1.20786477e-01,  6.61801335e-01, -3.47786223e-02,  5.60028641e-01,\n",
       "        4.05649388e-01,  3.17795915e-01, -3.42028552e-02,  1.07322766e+00,\n",
       "        5.31988622e-01,  0.00000000e+00,  4.05311972e-01,  1.22011622e-01,\n",
       "        2.14731166e-01,  7.27684194e-02,  2.49323697e-01,  2.48532722e-01,\n",
       "        4.29293727e-02,  2.29756051e-01,  5.49224214e-01, -6.93858704e-01,\n",
       "        7.55949920e-01,  5.10116897e-02,  1.65793490e-02,  2.29756051e-01,\n",
       "        2.71063038e-01, -3.91551614e-01, -1.32348052e-01,  7.55949920e-01,\n",
       "        3.53413537e-01,  2.57189015e-01,  4.05782297e-01,  1.35125337e-01,\n",
       "        6.26522732e-01, -5.34471732e-01,  5.49224214e-01,  6.61782577e-01,\n",
       "        1.62017079e-01,  5.48312018e-01, -2.68715410e-02,  9.19647030e-02,\n",
       "        5.79240653e-03,  4.05765912e-01, -1.32348052e-01, -3.15792928e-01,\n",
       "        3.83569042e-01,  0.00000000e+00,  6.26522732e-01, -2.64780745e-01,\n",
       "       -6.48982615e-01,  4.53890575e-01, -1.66101082e-02,  5.79240653e-03,\n",
       "       -2.90258683e-01,  6.69604863e-01,  5.10116897e-02,  1.29201536e-01,\n",
       "        1.50904948e-01,  4.07300263e-01,  6.20424122e-01,  3.53291702e-01,\n",
       "        6.26522732e-01,  4.14482378e-01,  6.25402437e-01,  1.64555781e-01,\n",
       "        6.62341816e-01, -2.68715410e-02,  5.90273996e-01,  4.93633952e-01,\n",
       "        0.00000000e+00,  3.81029184e-01, -1.32348052e-01,  5.49224214e-01,\n",
       "        4.69169086e-01,  4.65446462e-01,  0.00000000e+00,  6.83112171e-01,\n",
       "        4.05661489e-01, -4.19787923e-02,  2.49097157e-01,  1.56260313e-01,\n",
       "        3.53891232e-01,  2.49097157e-01,  3.52295372e-01, -9.83323738e-02,\n",
       "        1.29032022e-01,  1.24619598e-02,  0.00000000e+00,  4.74301469e-01,\n",
       "        7.51425055e-01,  1.29911541e-01,  5.41098278e-01,  0.00000000e+00,\n",
       "        3.07375866e-01,  4.06465011e-01, -4.19787923e-02,  2.14731166e-01,\n",
       "        6.26522732e-01,  8.57870421e-01])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svm.predict(X_cut)\n",
    "svm.save(\"../models/ranksvm.pkl\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "titles = np.load(\"../data/titles.npy\", allow_pickle=True)\n",
    "bodies = np.load(\"../data/bodies.npy\", allow_pickle=True)\n",
    "urls = np.load(\"../data/urls.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vectorizer\n",
    "vectorizer_body = TfidfVectorizer().fit(bodies)\n",
    "vectorizer_title = TfidfVectorizer().fit(titles)\n",
    "vectorizer_url = TfidfVectorizer().fit(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "import pickle\n",
    "\n",
    "with open(\"../models/vectorizer_body.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer_body, f)\n",
    "with open(\"../models/vectorizer_title.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer_title, f)\n",
    "with open(\"../models/vectorizer_url.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer_url, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embedding = vectorizer_title.transform(titles)\n",
    "body_embedding = vectorizer_body.transform(bodies)\n",
    "url_embedding = vectorizer_url.transform(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(\"../data/title_embedding.npz\", sp.csr_matrix(title_embedding))\n",
    "sp.save_npz(\"../data/body_embedding.npz\", sp.csr_matrix(body_embedding))\n",
    "sp.save_npz(\"../data/url_embedding.npz\", sp.csr_matrix(url_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
