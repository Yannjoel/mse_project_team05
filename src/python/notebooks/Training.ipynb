{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from RankingAlgorithms.neuralnetwork import NeuralNetwork\n",
    "from RankingAlgorithms.pwsvm import RankSVM\n",
    "from DataHandling.train_data import load_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_indices = [108, 18, 103, 3, 8, 13, 125, 126, 107, 17, 102, 2, 7, 12, 105, 15, 100, 0, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train, y_train = load_data(path=\"../../../data/MSLR-WEB10K/Fold1/train.txt\", nrows=10000, feature_indices=feature_indices)\n",
    "#X_test, y_test = load_data(path=\"../../../data/MSLR-WEB10K/Fold1/test.txt\", nrows=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts (array([0., 1., 2., 3., 4.]), array([5481, 3000, 1326,  142,   51]))\n"
     ]
    }
   ],
   "source": [
    "print('label counts', np.unique(y_train, return_counts=True))\n",
    "n_samples_per_class = np.unique(y_train, return_counts=True)[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 20) (255,)\n",
      "label counts:  (array([0., 1., 2., 3., 4.]), array([51, 51, 51, 51, 51]))\n"
     ]
    }
   ],
   "source": [
    "# balance dataset\n",
    "indices = []\n",
    "for label in range(5):\n",
    "    indices.append(list(np.random.choice(np.where(y_train == label)[0], n_samples_per_class, replace=False)))\n",
    "    \n",
    "indices = np.array(indices).flatten()\n",
    "\n",
    "X_cut = X_train[indices, :]\n",
    "y_cut = y_train[indices]\n",
    "\n",
    "print(X_cut.shape, y_cut.shape)\n",
    "print('label counts: ', np.unique(y_cut, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = torch.zeros(len(y_cut), 5)\n",
    "for i, label in enumerate(y_cut):\n",
    "    y_trans[i, 0:int(label)+1] = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(n_features=len(feature_indices), n_hidden=10, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define optimizer and loss fct\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.235372  [   32/  255]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.332633  [   32/  255]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5.008522  [   32/  255]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.502904  [   32/  255]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.550197  [   32/  255]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.224727  [   32/  255]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.303533  [   32/  255]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 5.106229  [   32/  255]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.909264  [   32/  255]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.294786  [   32/  255]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.931311  [   32/  255]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4.567747  [   32/  255]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 4.777458  [   32/  255]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 4.546021  [   32/  255]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4.775549  [   32/  255]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 4.973757  [   32/  255]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3.961844  [   32/  255]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 4.423182  [   32/  255]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 4.658817  [   32/  255]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 5.112282  [   32/  255]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 4.749082  [   32/  255]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4.560821  [   32/  255]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 5.099392  [   32/  255]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4.664961  [   32/  255]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.101103  [   32/  255]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.481741  [   32/  255]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.448180  [   32/  255]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 5.700856  [   32/  255]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 5.362585  [   32/  255]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4.714034  [   32/  255]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 4.790243  [   32/  255]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 5.151432  [   32/  255]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 5.235981  [   32/  255]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 5.018061  [   32/  255]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 4.170900  [   32/  255]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 4.752492  [   32/  255]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 4.062793  [   32/  255]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 4.352704  [   32/  255]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 4.083155  [   32/  255]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 4.932810  [   32/  255]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 5.140160  [   32/  255]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 4.707036  [   32/  255]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 5.049657  [   32/  255]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 4.987682  [   32/  255]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 4.439122  [   32/  255]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 3.991071  [   32/  255]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 5.552629  [   32/  255]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 4.917278  [   32/  255]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 4.396637  [   32/  255]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 4.149534  [   32/  255]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 4.182857  [   32/  255]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 4.693263  [   32/  255]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 4.741223  [   32/  255]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 4.038378  [   32/  255]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 4.325237  [   32/  255]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 4.461959  [   32/  255]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 4.459248  [   32/  255]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 4.498996  [   32/  255]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 4.714644  [   32/  255]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 4.002872  [   32/  255]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 4.973384  [   32/  255]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 4.244452  [   32/  255]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 4.518785  [   32/  255]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 4.449806  [   32/  255]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 5.117362  [   32/  255]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 5.355730  [   32/  255]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 4.670737  [   32/  255]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 4.707128  [   32/  255]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 4.671378  [   32/  255]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 5.008790  [   32/  255]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 3.941973  [   32/  255]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 4.946917  [   32/  255]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 4.397324  [   32/  255]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 4.328852  [   32/  255]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 4.387022  [   32/  255]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 4.276722  [   32/  255]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 4.940124  [   32/  255]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 4.337467  [   32/  255]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 4.170398  [   32/  255]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 5.372344  [   32/  255]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 4.271321  [   32/  255]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 4.902397  [   32/  255]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 4.560455  [   32/  255]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 5.231263  [   32/  255]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 4.262677  [   32/  255]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 4.634054  [   32/  255]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 4.423388  [   32/  255]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 4.926004  [   32/  255]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 4.341431  [   32/  255]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 4.110749  [   32/  255]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 4.511716  [   32/  255]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 4.731476  [   32/  255]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 5.057587  [   32/  255]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 4.260242  [   32/  255]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 4.855932  [   32/  255]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 4.706937  [   32/  255]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 4.311194  [   32/  255]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 4.609207  [   32/  255]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 4.028366  [   32/  255]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 4.841150  [   32/  255]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = model.train_loop(torch.Tensor(X_cut), y_trans, loss, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.2\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(torch.Tensor(X_cut))\n",
    "print('accuracy: ', np.sum(np.array(y_pred) == np.array(y_cut)) / len(y_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([204,  51]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(y_pred) == np.array(y_cut), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([255]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999999999994"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg_score(y_cut.reshape(1, -1), y_pred.reshape(1, -1), k=20)\n",
    "ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mdoel\n",
    "model.save(\"../models/nn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/annavollweiter/Documents/Uni/MSE/mse_project_team05/.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = RankSVM(load=False)\n",
    "svm.fit(X_cut, y_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.76793399e+00, -4.86979760e+00, -1.16243722e+01, -7.87352797e+00,\n",
       "       -5.46389431e+00, -1.28447799e+01, -8.65985065e-01,  1.56246046e-01,\n",
       "       -1.88554148e+00, -6.41238396e+00, -9.48179586e-01, -1.83691934e+00,\n",
       "       -9.41967821e-01, -6.17026194e-01, -6.73894076e+00, -9.21920136e-01,\n",
       "       -6.55795737e+00, -1.30042793e+00, -3.77519488e+00, -3.24899065e+00,\n",
       "       -1.81251054e+00, -6.19496705e-01,  1.83292444e-01, -6.05044307e+00,\n",
       "       -6.67430998e+00, -2.04984044e+00, -7.02932425e-01, -4.66791753e+00,\n",
       "       -2.05567515e-01, -7.17213089e+00, -4.50693459e-01, -2.04947909e+00,\n",
       "       -1.27292429e+00, -4.33680659e+00, -2.19481581e+00, -1.18554889e+00,\n",
       "       -7.18551069e+00, -5.06002081e+00, -4.50050433e+00, -6.93675671e-01,\n",
       "       -4.19411620e+00, -5.56314055e-01, -1.93361801e+01, -5.35237221e+00,\n",
       "       -1.25420656e+00, -3.71445085e+00, -5.46829891e+00, -2.16658268e+00,\n",
       "       -3.25423227e+00,  6.33638358e-01, -4.12400614e+00, -1.37828927e+00,\n",
       "       -2.44093662e+00, -3.99734472e+00, -1.18042422e+00, -6.11853545e+00,\n",
       "       -1.24528053e+00, -7.48817277e-01, -2.11093983e+01, -8.57021576e-01,\n",
       "       -3.24063234e+00, -1.53461117e+00, -7.41279029e-01, -1.22362575e+00,\n",
       "       -7.51828559e+00, -1.52378393e+01, -2.28262604e+00, -3.16934020e-01,\n",
       "       -1.52392934e+00, -1.87776633e+00, -2.73819624e+00, -1.99619121e+00,\n",
       "       -1.10895549e-02, -1.20554285e+00, -1.32809250e+01, -4.73365877e+00,\n",
       "       -1.44725063e+00, -2.69931332e+00, -1.86474248e+00, -4.34489803e+00,\n",
       "       -9.07742221e-01, -5.06179325e+00, -2.35872711e+00, -3.34925990e+00,\n",
       "       -3.24423685e+00, -3.91396943e+00, -5.42383318e-01, -3.78628420e+00,\n",
       "       -3.32502407e+00, -2.99073695e+00, -3.46218140e+00, -1.02075952e+00,\n",
       "       -2.03582300e+01, -3.67371416e+00, -4.23971252e+00, -2.92423946e+00,\n",
       "       -2.20465770e+00, -2.96168821e+00, -5.41496234e+00, -2.31136482e+00,\n",
       "       -5.00832190e+00, -7.43782036e-01, -1.79363843e+00, -2.00866882e+00,\n",
       "       -1.42721997e+00, -3.83109518e-01, -2.63609820e+00, -6.01944610e+00,\n",
       "       -2.61785291e+00, -9.56480831e-01, -2.11638087e+00, -6.92069014e-01,\n",
       "       -3.65126874e+00, -7.95228318e-01, -1.72694228e+00, -4.95736093e+00,\n",
       "       -3.19007768e+00, -4.26279628e+00, -1.94985974e+00, -3.66888532e+00,\n",
       "       -1.64173691e+00, -4.20464033e+00, -1.55041393e-01, -1.47809132e+00,\n",
       "       -2.68096917e+00, -3.65103088e-01, -2.65769761e+00, -4.75737655e-01,\n",
       "       -1.09259567e+00, -1.19982698e-01, -1.07832648e+00, -2.85635172e+00,\n",
       "       -9.56506283e-01, -3.32500833e+00, -6.27977299e-01, -8.56319691e+00,\n",
       "       -1.66671010e+00, -2.23330975e+00, -4.98846861e-01, -3.68959457e+00,\n",
       "       -3.53590055e-01, -7.15996779e+00, -2.32934630e+00, -1.30289277e-01,\n",
       "       -6.81933523e+00, -9.41485645e-01, -3.49465578e+00, -2.25003012e-01,\n",
       "       -2.57943645e+00, -1.89649418e+00, -3.78488878e-01,  6.37338392e-02,\n",
       "       -7.57416867e-01, -1.74792095e+00, -4.61030986e+00, -1.43752594e+00,\n",
       "       -1.24487687e+00, -9.08460255e-02, -2.04542794e+00, -3.20539150e+00,\n",
       "       -2.06648921e+00, -1.16169673e+00, -1.25825678e+00, -2.48653420e+00,\n",
       "       -5.33896471e+00, -6.28094676e-02, -1.38460205e+00, -3.63691083e+00,\n",
       "       -3.41764107e-01, -1.49142223e+00, -1.25892556e+01, -2.11982269e-01,\n",
       "       -2.09912249e+00, -1.59883103e+00,  2.56197685e-01, -4.22321103e+00,\n",
       "       -5.73317704e+00, -6.09964120e+00, -3.55058219e+00, -2.31493360e+00,\n",
       "       -1.01435605e+00, -2.48652158e+00, -1.53560209e+00, -8.97926233e-02,\n",
       "       -1.60432513e+00, -1.16996236e+00, -1.51739254e-01, -1.13604311e+00,\n",
       "       -1.23356312e+00, -6.53536738e-01, -1.16253466e+00, -8.03325468e+00,\n",
       "       -1.04226276e+00, -1.62582312e+00, -1.64728766e+00, -1.61772472e+00,\n",
       "       -1.18373158e+00, -4.63617729e-01, -5.18937210e-01, -1.54538616e+00,\n",
       "       -1.25397172e+00, -1.20050761e+00, -1.25949540e+01, -5.98075199e-01,\n",
       "       -4.81570301e-01, -2.63872220e-01, -1.30366601e+00, -5.24811425e-01,\n",
       "        2.90168203e-01, -2.30856571e+00, -9.90361125e-01, -2.74733428e-01,\n",
       "       -2.21195430e+00, -9.42794321e-01, -9.06874741e-01, -9.29616248e-01,\n",
       "       -5.02106620e-02,  7.38278380e-01, -8.86498863e-01, -4.95170904e-01,\n",
       "       -1.56622229e+00,  6.94161578e-01,  9.86799824e-02, -5.65147406e-01,\n",
       "       -1.25399807e+00, -4.59339269e+00, -2.85021541e-01,  4.89050916e-01,\n",
       "       -7.28219786e-01, -4.02061563e-01,  7.83985158e-01, -1.42935099e+00,\n",
       "        1.86984990e-01,  4.49426635e-01, -1.68522826e-01, -3.39309616e-01,\n",
       "       -4.93628811e-01,  1.57745779e-01, -2.57435314e+00, -1.15636154e+00,\n",
       "       -2.34923721e+00, -1.30425755e+00, -1.22622849e+00, -3.30692199e-01,\n",
       "        2.53461798e-01, -1.27715851e+00, -3.44177340e-01, -2.21617254e-02,\n",
       "       -2.58251984e-01, -5.70738605e-01, -9.26108452e-02, -3.42155758e-01,\n",
       "       -1.27184349e+00, -1.60901129e+00, -1.62914956e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svm.predict(X_cut)\n",
    "svm.save_coef(\"../models/ranksvm_coef.pkl\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887853830146255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg_score(y_cut.reshape(1, -1), preds.reshape(1, -1), k=10)\n",
    "ndcg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
